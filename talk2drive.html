<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>Talk2Drive|Purdue Digital Twin Lab</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>
    <link rel="icon" href="images/icon_36_36.png"/>
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css"/>
    </noscript>
</head>

<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Header -->
    <header id="header">
        <a href="index.html" class="logo">LLM4AD</a>
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul class="links">
            <li><a href="index.html">Overview</a></li>
            <li class="active"><a href="talk2drive.html">Talk2Drive</a></li>
            <!-- <li><a href="generic.html">Demos</a></li> -->
            <li><a href="3R.html">3R</a></li>
            <li><a href="survey.html">Survey</a></li>
            <li><a href="lampilot.html">Lampilot</a></li>
            <!-- <li class="active"><a href="elements.html">Elements Reference</a></li> -->
        </ul>

    </nav>

    <!-- Main -->
    <div id="main">

        <!-- Post -->
        <section class="post">
            <center>
                <h2>Large Language Models for Autonomous Driving: Real-World Experiments<br/></h2>
            </center>


            <center>
                <h4>Can Cui, Zichong Yang, Yupeng Zhou, Yunsheng Ma, Juanwu Lu, Lingxi Li, Yaobin Chen,
                     Jitesh H. Panchal and Ziran Wang<br/></h4>
            </center>
            <ul class="actions special">
                <li><a href="https://arxiv.org/abs/2312.09397" class="button large">Paper</a></li>
            </ul>
            <p>Talk2Drive Framework is the first successful implementation of an LLM-based autonomous driving
                system in a real-world vehicle. This approach aims to overcome several key challenges faced by
                traditional autonomous driving systems.<br/></p>
            <header>
                <p>Key Features:<br/>
                    1. It transforms verbal commands from humans into textual instructions, which are then processed
                    by LLMs in the cloud.<br/>
                    2. LLMs generate specific driving codes that are executed by the autonomous vehicle, adjusting
                    driving behaviors and control parameters to align with the human preferences.<br/>
                    3. A memory module in the vehicle stores all human-vehicle interaction data, ensuring each
                    driving experience is personalized based on the human’s historical preferences and commands. <br/>

                    <a href="#" class="image main"><img src="images/t2d.png" alt=""/></a>


                <hr/>
                <p><span class="image right"><img src="images/main_update.png" alt=""/></span>Talk2Drive framework
                    architecture.
                    A human's spoken instructions are processed by cloud-based LLMs,
                    which synthesize contextual data C from weather, traffic conditions, and local traffic rules
                    information.
                    The LLMs generate executable codes P that are communicated to the vehicle's Electronic Control
                    Unit (ECU).
                    These codes operate the actuation of vehicle controls, ensuring that the human's intent is
                    translated into safe
                    and personalized driving actions. A memory module archives every command I, its resultant codes
                    P, and
                    subsequent user feedback F, ensuring continuous refinement of the personalized driving
                    experience.
                </p>
                <!-- <h2>Talk2Drive Framework Architecture</h2>
                                Talk2Drive framework architecture. A human's spoken instructions are processed by cloud-based LLMs,
                                which synthesize contextual data C from weather, traffic conditions, and local traffic rules information.
                                The LLMs generate executable codes P that are communicated to the vehicle's Electronic Control Unit (ECU).
                                 These codes operate the actuation of vehicle controls, ensuring that the human's intent is translated into safe
                                  and personalized driving actions. A memory module archives every command I, its resultant codes P, and
                                  subsequent user feedback F, ensuring continuous refinement of the personalized driving experience.
                                <div class="image main"><img src="images/main_update.png" alt="" /></div> -->

                <hr/>
                <header>
                    <h2>Autonomous driving function modules and message flow</h2>
                    <!-- <p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p> -->
                </header>
                <p><span class="image left"><img src="images/workflow.png" alt=""/></span>The initial step in the
                    Talk2Drive framework involves directly receiving arbitrary verbal commands from humans.
                    Utilizing
                    cutting-edge voice recognition technology, specifically the open-source API Whisper, these
                    verbal commands are accurately
                    captured and then translated into textual instructions (I).The LLMs then generate corresponding
                    codes (P) based on this
                    interpretation.The generated codes P are sent back from the cloud to the vehicle's Electronic
                    Control Unit (ECU), where they are executed.
                    The code execution involves adjusting basic driving behaviors and various parameters in the
                    vehicle’s planning and control
                    systems. After ECU executes these codes, the vehicle's actuators control the throttle, brakes,
                    gear selection, and steering
                    to realize the driving behavior specified by the LLM-generated codes through the CAN bus and
                    drive-by-wire system.
                </p>
                <!-- <div class="image main"><img src="images/pic01.jpg" alt="" /></div> -->
                <hr/>
            </header>
            <h2>Vehicle Setup</h2>
            <div class="row">
                <div class="col-6 col-12-small">

                    <h3>Sensors</h3>
                    <ul>
                        <li>One VLP-32C Lidar.</li>
                        <li>Two mako G-319C Cameras.</li>
                        <li>Two Logitech C920s In-Cabin Cameras.</li>
                        <li>Cradlepoint IBR900 Series Router with AT&T Sim Card.</li>
                    </ul>
                </div>
                <div class="col-6 col-12-small">

                    <h3>Spectra ECU</h3>
                    <ul>
                        <li>Intel I9-9900 9th Gen 3.10/5.0GHz Hexa-
                            core 65W Processor .
                        </li>
                        <li>NVIDIA Quadro RTX-A4000
                            16GB GDDR6 140W GPU.
                        </li>
                        <li>512GB SSD.</li>
                    </ul>
                </div>

                <h3>Localization:</h3>
                <p>3D-NDT Mapping</p>
                <div class="image main"><img src="images/sensor_setup.png" alt=""/></div>
                <hr/>
                <section class="post">
                    <h2>Demos</h2>
                    <header class="major">
                        <!-- <span class="date">April 25, 2017</span> -->
                    </header>
                    <!-- <div class="image main"><img src="images/pic01.jpg" alt="" /></div> -->
                    <div class="container">
                        <div class="row gtr-200">
                            <div class="col-9 col-12-medium">
                                <h3>Talk2Drive Framework on Highway</h3>
                                <iframe width="900" height="500"
                                        src="https://www.youtube.com/embed/nmro99dFVn8?si=VKPVmt4b_tU2an8I"
                                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                        allowfullscreen></iframe>
                            </div>
                </section>
                <section class="post">
                    <header class="major">

                        <!-- <span class="date">April 25, 2017</span> -->
                    </header>
                    <!-- <div class="image main"><img src="images/pic01.jpg" alt="" /></div> -->
                    <div class="container">
                        <div class="row gtr-200">
                            <div class="col-9 col-12-medium">
                                <h3>Talk2Drive Framework on Intersection</h3>
                                <iframe width="900" height="500"
                                        src="https://www.youtube.com/embed/dTG1_bH5DbE?si=SjLRfUry0q-2xEhI"
                                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                        allowfullscreen></iframe>
                            </div>
                </section>
                <section class="post">
                    <header class="major">
                        <!-- <span class="date">April 25, 2017</span> -->

                    </header>
                    <!-- <div class="image main"><img src="images/pic01.jpg" alt="" /></div> -->
                    <div class="container">
                        <div class="row gtr-200">
                            <div class="col-9 col-12-medium">
                                <h3>Talk2Drive Framework on Parking Lot</h3>
                                <iframe width="900" height="500"
                                        src="https://www.youtube.com/embed/RY8Rdt0Sobk?si=ei41vKYgVfa6AtW_"
                                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                                        allowfullscreen></iframe>
                            </div>
                </section>
            </div>
            <hr>
            <div style="overflow-x: auto;">
                <table style="width:100%">
                    <h2> Contributors</h2>
                  <tr>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/can.jpg" height="160"></td>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/zichong.jpg" height="160"></td>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/yupeng.png"" height="160"></td>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/yunsheng.jpg" height="160"></td>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/juanwu.jpg" height="160"></td>
                  </tr>
                  <tr>
                    <td style="text-align:center"><a href="https://cancui19.github.io/">Can Cui</a> <br> Purdue University</td>
                    <td style="text-align:center"><a href="https://www.linkedin.com/in/zichong-yang-002791218/?trk=people-guest_people_search-card">Zichong Yang</a> <br>Purdue University</td>
                    <td style="text-align:center"><a href="https://www.linkedin.com/in/yupeng-zhou-313765261/">Yupeng Zhou</a> <br>Purdue UNiversity</td>
                    <td style="text-align:center"><a href="https://maysonma.github.io/">Yunsheng Ma</a> <br>Purdue University</td>
                    <td style="text-align:center"><a href="https://www.linkedin.com/in/juanwu-lu-35a9951b8">Juanwu Lu</a> <br>Purdue University</td>
                  </tr>
                  <tr>
                    <td style="text-align:center"><img src="profiles/llx.png" height="160"></td>
                    <td style="text-align:center"><img src="profiles/ybc.jpg" height="160"></td>
                    <td style="text-align:center"><img src="profiles/JP.jpeg" height="160"></td>
                    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/prof_wang.jpg" height="160"></td>
                    <!-- <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Tong_Zhou.jpg" height="100"></td> -->
                  </tr>
                  <tr>
                    <td style="text-align:center"><a href="https://et.iupui.edu/people/ll7">Lingxi Li</a> <br>IUPUI</td>
                    <td style="text-align:center"><a href="https://et.iupui.edu/people/ychen">Yaobin Chen</a> <br> IUPUI </td>
                    <td style="text-align:center"><a href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=80194">Jitesh H. Panchal</a> <br>Purdue University</td>
                    <td style="text-align:center"><a href="https://ziranw.github.io">Ziran Wang</a> <br>Purdue University</td>
                    <!-- <td style="text-align:center"><a href="">Tong Zhou</a> <br> Tencent</td> -->
                  </tr>
                </table>
              </div>
    </div>

    <!-- Copyright -->
    <div id="copyright">
        <ul>
            <li>&copy; Purdue Digital Twin Lab</li>
            <li>Lab Website: <a href="https://purduedigitaltwin.github.io">purduedigitaltwin.github.io</a></li>
        </ul>
    </div>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>

</html>